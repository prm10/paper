# 摘要
　　提出了一种用于异常检测的RNN（貌似不同于循环神经网络，叫replicator neural networks）。然后将该算法与其他三种算法在公开的数据集上做了对比。较小的数据集可以洞悉RNN的原理和不足，较大的数据集可以证明其可扩展性和实用价值。论文还提供了对比异常检测能力的流程和基准。
# 简介
　　异常点往往被认为是回归模型中的残差或者密度模型中的远离点
　　介绍了参数化方法和非参数化方法的差异，本文方法是非参数化方法。
# 用于异常检测的RNNs
　　RNN结构如下图（感觉跟NN没啥区别），除了输入输出，就是三个隐藏层，输出的拟合目标值就是输入。为了使得输出是离散值，激活函数设计成了右图这种奇葩曲线。
![网络结构和激活函数](http://img.blog.csdn.net/20160127162021865)
　　此外还定义了异常度(Outlier Factor)，$OF_i$代表第$i$个数据的重构误差平均值。这样就可以用$OF_i$来给每个点打分。
# 异常检测方法的对比
　　异常检测的方法（包括聚类、预估等方法）浩如烟海，如果真的要一一对比，可以另写一篇paper啦，所以就先只列出三种方法。
# 实验设计
　　每种异常检测方法对于异常判定都有各自的偏向。需要通过多种数据集来探究不同方法的偏向，然后研究针对数据集的特点来用适合该特点的特定异常检测方法。
　　统计学中考虑了三种定性的异常。聚类异常(Cluster outliers)发生在方差很小的聚类中，放射状异常(Radial outliers)是指偏离了数据分布的主轴方向。散布异常(Scattered outliers)就是随机的出现在一些地方。
　　实验所用数据集包含以上三种异常值的不同组合。统计学中往往将污染等级定为超过40%，而数据挖掘中往往指数量级小于4%的部分。对于欺诈等罕见异常值，显然后者的定义更加合适。
　　可以发现，来自统计学数据集的异常主要是测量误差或者数据错误，而来自数据挖掘数据集的异常往往是因为属于不同的类别。
# 实验结果
## HBK
　　HBK是一个人工构建的数据集，有14个异常值（太少了点吧）。基于回归的方法一般只能找到头10个。而这10个远远偏离正常数据的中心或者远离回归的平面。剩下的4个点没有这么弱，虽然也远离正常数据，但是离回归面比较近。
　　算法对比就不说了，这个数据集太扯了点。
## Wood Data
>The Wood dataset consists of 20 observations with data points 4, 6, 8, and
19 being outliers

　　很难通过观测直接判断异常点。实验结果就不细说了，跟写实验报告差不多。
## Wisconsin Breast Cancer Dataset
　　这个数据集大家普遍反映很难辨别异常。所以我们就在恶性程度8.07% to 35%的数据上进行了采样。
　　这些方法普遍随着恶性程度的降低，辨识性能下降。（异常值甚至比正常值更多的时候，就不叫异常检测，而应该是二分类问题了吧）
## Network Intrusion Detection
　　这个数据包含了一个网络连接的信息，包括了传输的bytes和连接的类别。在原始数据集中有将近五十万个事件，并打上了标签，分为入侵和非入侵。
　　我们选择了41个被认为与入侵高度相关的特征。
>The original dataset contained 4,898,431 data records, including 3,925,651
attacks (80.1%).

　　显然，入侵比非入侵多这么多，搞不了异常检测，所以又对入侵数据采样了。最终使得入侵数据仅占0.48%。
　　接着，根据服务类型，又将这些数据细分为5类，旨在在各个类别中找出异常。
　　结果就是几个表和图。
